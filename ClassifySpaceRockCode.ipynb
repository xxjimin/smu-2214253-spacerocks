{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 이미지 식별 머신을 위한 데이터를 준비한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 필요한 라이브러리를 불러 온다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, optim\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 토치비전 라이브러리\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms, models\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 이미지 처리 라이브러리 (PIL, pillow)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchvision/_meta_registrations.py:25\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroi_align\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchvision/_meta_registrations.py:18\u001b[39m, in \u001b[36mregister_meta.<locals>.wrapper\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(fn):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension\u001b[49m._has_ops():\n\u001b[32m     19\u001b[39m         get_meta_lib().impl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch.ops.torchvision, op_name), overload_name), fn)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
            "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "# 데이터 플로팅 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "# 숫자 처리 라이브러리\n",
        "import numpy as np\n",
        "# 딥러닝을 위한 파이토치 라이브러리\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "# 토치비전 라이브러리\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "# 이미지 처리 라이브러리 (PIL, pillow)\n",
        "from PIL import Image\n",
        "# 주피터 노트북에서 plot이 보이도록 설정\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
        "\n",
        "\n",
        "\n",
        "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (확인) 변환 방법을 출력하여 확인해 본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
        "print(t_transforms)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 로더 함수를 작성한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (연습) trainloader와 testloader를 만들어 본다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 학습 데이터의 형식을 확인한다.\n",
        "print(train_data)\n",
        "\n",
        "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
        "print(len(train_data), len(test_data))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. 데이터세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
        "\n",
        "\n",
        "\n",
        "print(indices)\n",
        "\n",
        "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
        "\n",
        "\n",
        "\n",
        "print(indices)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
        "\n",
        "\n",
        "print(split)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
        "\n",
        "\n",
        "\n",
        "print(train_idx)\n",
        "print(test_idx)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
        "\n",
        "\n",
        "\n",
        "# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.\n",
        "print(trainloader.dataset.classes)\n",
        "print(testloader.dataset.classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 코드들을 묶어서 load_split_train_test() 함수를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)\n",
        "\n",
        "def load_split_train_test(data_dir, valid_size) :\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return trainloader, testloader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load_split_train_test() 함수를 이용하여 trainloader, testloader를 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(trainloader.dataset.classes)\n",
        "print(testloader.dataset.classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 이미지 데이터 샘플들을 살펴본다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 임의의 데이터를 로딩한 후 이미지와 레이블을 반환하는 get_random_images() 함수를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_images(num) :\n",
        "\n",
        "    data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "\n",
        "    # loader에서 데이터를 한 개씩 꺼내 주는 iterator를 생성한다.\n",
        "\n",
        "\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 임의 선택한 이미지를 표시해 본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5개의 이미지와 레이블을 랜덤하게 가져온다.\n",
        "\n",
        "\n",
        "# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.\n",
        "to_pil = transforms.ToPILImage()\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "# 학습 데이터의 class 리스트를 얻는다.\n",
        "\n",
        "\n",
        "\n",
        "# 이미지를 표시하기 위한 설정을 한다.\n",
        "for ii in range(len(images)) :\n",
        "    image = to_pil(images[ii])\n",
        "    sub = fig.add_subplot(1, len(images), ii+1)\n",
        "    index = labels[ii].item()\n",
        "    sub.set_title(classes[index])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "# 이미지를 표시한다.\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet50 모델을 가져와 FCL(Fully Connected Layer)을 수정한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute device를 정한다(CPU or GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute device를 정하고 확인한다.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 사전학습된 ResNet50 모델을 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resnet50 모델을 pretrained=True로 설정한다.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (확인) 수정 전의 ResNet50 모델을 확인해 본다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FCL을 수정한다.(뉴런 구축, 신경망 연결, FCL의 layer 설정 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모든 신경망 구축 : 전이학습을 위해 모델의 가중치를 freeze 한다.\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 뉴런들을 연결하여 신경망을 생성한다.\n",
        "\n",
        "model.fc = \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 손실함수를 Cross entropy loss 함수로 지정한다.\n",
        "\n",
        "\n",
        "# optimizer를 Adam으로 지정한다.\n",
        "\n",
        "\n",
        "# 신경망을 compute device로 보낸다.\n",
        "model.to(device)\n",
        "\n",
        "# 종료 여부를 출력한다.\n",
        "print('done!')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (확인) FCL을 확인해 본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model.fc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 모델의 FCL을 학습시키고 테스트 한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 학습/검증을 위한 변수를 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 에폭 및 출력 간격을 설정한다.\n",
        "epochs = 10\n",
        "print_every = 5\n",
        "\n",
        "# 손실 변수들을 초기화 한다.\n",
        "running_loss = 0\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.\n",
        "steps = 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 설정한 에폭만큼 모델을 학습시키며 검증/평가 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 설정한 회수만큼 학습 후 검증한다.\n",
        "for epoch in range(epochs) :\n",
        "    # 에폭을 count 한다.\n",
        "    epoch += 1\n",
        "    # trainloader에서 이미지와 레이블을 하나씩 가져온다.\n",
        "    for inputs, labels in trainloader:\n",
        "        # 학습 단계를 count 하고 출력한다.\n",
        "        steps += 1\n",
        "        print('Training step ', steps)\n",
        "        # 입력 데이터(이미지, 레이블)를 device로 이동시킨다.\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # 기존에 학습된 gradient 값을 초기화 한다.(이전에 학습한 값이 영향을 주지 않도록 함)\n",
        "        optimizer.zero_grad()\n",
        "        # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
        "        logps = model.forward(inputs)\n",
        "        # 손실함수를 이용하여 손실(loss)값을 계산한다.\n",
        "        loss = criterion(logps, labels)\n",
        "        # 손실값을 기준으로 gradient를 update한다.\n",
        "        loss.backward()\n",
        "        # gradient를 이용하여 설정된 optimizer로 가중치를 update한다.\n",
        "        optimizer.step()\n",
        "        # 손실값을 누적/계산한다.\n",
        "        running_loss += loss.item()\n",
        "        # 학습 단계 5회마다 모델을 테스트/평가 한다.\n",
        "        if steps % print_every == 0:\n",
        "            # 손실과 정확도 변수를 초기화 한다.\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            # 모델 평가 모드로 전환한다. (드롭아웃 등을 비활성화)\n",
        "            model.eval()\n",
        "            # 모델 평가 시 gradient를 계산하지 않도록 한다.\n",
        "            with torch.no_grad():\n",
        "                # testloader에서 이미지와 레이블을 하나씩 가져온다.\n",
        "                for inputs, labels in testloader:\n",
        "                    # 입력 데이터(이미지, 레이블)를 device로 이동시킨다.\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
        "                    logps = model.forward(inputs)\n",
        "                    # 손실함수로 손실(loss) 값들을 계산한다.\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    # 손실값을 누적시킨다.\n",
        "                    test_loss += batch_loss.item()\n",
        "                    # 로그 확률을 실제 확률값으로 변환한다.\n",
        "                    ps = torch.exp(logps)\n",
        "                    # 가장 큰 확률값과 class를 얻는다. (topk : 상위 k번째까지의 값)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    # 정답 레이블들을 top_class와 동일한 형태로 바꾼 후 값을 비교하여, 맞춘 값들을 얻는다.\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    # equals를 float 텐서로 바꾼 후 평균 정확도를 누적/계산한다.\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            # 학습 손실값과 테스트 손실값을 추가한다.\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))\n",
        "            # 학습 손실값, 테스트 손실값, 테스트 정확도를 출력한다.\n",
        "            print(\"Epoch {}/{}: \".format(epoch, epochs),\n",
        "                  \"Train loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                  \"Test loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "                  \"Test accuracy: {:.3f}\\n\".format(accuracy/len(testloader))) \n",
        "            # running_loss 값을 초기화 한다.\n",
        "            running_loss = 0\n",
        "            # 모델 학습 모드로 전환한다.\n",
        "            model.train()\n",
        "            break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (확인) 학습 손실값과 테스트 손실값을 그래프로 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "plt.plot(train_losses, label='training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 학습/테스트 완료된 모델을 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 추후 로드하여 사용할 수 있도록 학습/테스트 완료된 모델을 저장한다.\n",
        "torch.save(model, 'moonrockmodel.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 완성된 모델을 사용하여 예측한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 저장한 모델을 불러온다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 저장한 모델을 불러온다.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = torch.load('moonrockmodel.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (확인) 불러온 모델을 확인해 본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 이미지 예측을 위해 predict_image() 함수를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image):\n",
        "    image_tensor = t_transforms(image).float()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5개의 이미지를 임의로 가져와 예측해 본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 평가 모드로 전환한다.\n",
        "\n",
        "\n",
        "\n",
        "# ToPILImage 변환을 이용하여 텐서 이미지를 PIL 이미지로 변경하는 변환 설정\n",
        "to_pil = transforms.ToPILImage()\n",
        "\n",
        "# 5개의 이미지를 랜덤하게 가져온다.\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "# 데이터의 class 목록을 얻는다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5개의 이미지에 대해 반복 수행한다.\n",
        "for ii in range(len(images)):\n",
        "    # 이미지를 PIL 이미지로 변환한다.\n",
        "    image = to_pil(images[ii])\n",
        "    # 이미지에 대해 예측 후, 예측된 class를 얻는다.\n",
        "    \n",
        "\n",
        "\n",
        "    # 이미지 아래에 class를 표시하도록 설정한다.\n",
        "    sub = fig.add_subplot(1, len(images), ii+1)\n",
        "    res = labels[ii].item() == index\n",
        "    sub.set_title(classes[index] + ':' + str(res))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
